# ğŸ¯ Vision Statement

1. ğŸ”„ ğŸ¤– Fully automated (Partially - Ansible playbooks exist, need GitLab/Rundeck orchestration)
2. âœ… ğŸ” SSH free for 99% of tasks (Cloudflare tunnels + Access policies deployed)
3. âœ… ğŸ›¡ï¸ Everything secured with publicly signed certs (Let's Encrypt via Cloudflare)
4. âœ… ğŸ“ Git driven infrastructure as code (All playbooks in Git, idempotent)
5. ğŸ”„ ğŸ—ï¸ Git driven build for services / containers (GitLab not deployed yet)
6. âŒ ğŸ“Š Log aggregation service (Loki not deployed)
7. âŒ ğŸ›ï¸ Control plane for building infrastructure (Rundeck/Semaphore not deployed)
8. âŒ ğŸ¢ Isolated "clusters" and "environments" / dev-prod
9. ğŸ”„ ğŸ·ï¸ Versioned releases (Docker images with SHA tags for TinaCMS)
10. âŒ ğŸŒ iBGP we can use MetalLB / Cilium LoadBalancer in BGP modes
11. ï¿½ ï¿½ Service discovery for both Docker and Kubernetes (Docker DNS via container names, K8s not deployed)
12. âŒ âš¡ HA for all critical components (DNS, DHCP, LB)
13. âŒ ğŸ› ï¸ Resiliency and Redundancy to achieve higher reliability
14. âŒ ğŸš¨ DR plan for all services config and data, recover / restore within x mins
15. âœ… ğŸ§  Local LLM RAG (llama.cpp + open-webui deployed with GPU support)

# ğŸ—ï¸ Architecture

## ğŸ“¦ GitHub stores the Ansible playbooks

1. âœ… ğŸ’» Laptop creates control plane metal
2. âœ… ğŸ“š Git repo, build server backs up to GitHub (All playbooks in homelab repo)

## ğŸ–¥ï¸ Control plane metal

1. âœ… ğŸŒ DHCP DNS setup by manual install (DNS running with bind9 + DDNS)
2. âŒ ğŸ“¡ PXE TFTP GitLab manual install
3. âŒ ğŸš€ GitLab deploys Rundeck
4. âŒ âš™ï¸ PXE boot automated install of Proxmox
5. âŒ ğŸ–¥ï¸ Rundeck creates VMs on Proxmox metals
6. âŒ ğŸ”§ Run Ansible playbooks with Rundeck for web UI, maybe build server triggers Rundeck tasks
7. âŒ ğŸ‘€ Maybe Rundeck just watches the repo for changes

## ğŸ  Proxmox

1. âŒ âš¡ HA for both metals, allowing control plane VMs to migrate between
2. ğŸ”„ _[Additional Proxmox items to be added]_

aybooks

1. âŒ ğŸ­ Ansible Semaphore - https://semaphoreui.com/
2. âŒ ğŸ” Investigate Temporal also - https://hub.docker.com/r/temporalio/server
3. âœ… â™»ï¸ All idempotent (All 20+ playbooks are idempotent)
4. âœ… âœï¸ Writes all configuration (Docker compose, systemd services, configs)
5. âœ… ğŸ—ï¸ Creates Infrastructure (Services, networks, volumes, directories)
6. âœ… ğŸ” Perform investigation actions (Health checks implemented)
7. âœ… ğŸ”„ Restarts services on config change (CI/CD) (Handlers restart on changes)
8. âŒ ğŸ–¥ï¸ VM creation ready to be configured


## ğŸ¦Š GitLab vs Rundeck Ansible separation of concern

1. ï¿½ ï¿½ Automate email configuration (Postfix configured for GitLab, not deployed)
2. âŒ ğŸ”‘ Automate set default root password
3. âŒ ğŸ³ GitLab builds container images
4. âŒ ğŸ”„ GitLab will install and keep Rundeck updated
5. âŒ âš™ï¸ GitLab will only produce config to be run by Rundeck / Ansible
6. âœ… ğŸ—ï¸ Rundeck / Ansible is responsible for all IaC (Ansible handles all IaC currently)

## ğŸŒŠ Ocean to node006 Proxmox host

1. âŒ ğŸ’¾ Decide on Proxmox boot disk configuration
2. âœ… ğŸ”„ Convert all ocean services to Ansible in Git (20+ services deployed)
3. âŒ ğŸ–¥ï¸ Create VM with ocean SSD passthrough
4. âŒ ğŸ“¦ Export / import data01 ZFS pool from ocean â†’ node006

---

# âœ… Completed Items

## Infrastructure & Services

1. âœ… â™»ï¸ Rewrite playbooks so they are idempotent (All 20+ playbooks idempotent)
2. âœ… ğŸ§ Docker container for Audible download and convert (Deployed with playbook)
3. âœ… â˜ï¸ NextCloud Ansible playbook (Deployed with MariaDB + Redis)
4. âœ… ğŸ” Vault for secrets (ansible-vault for all sensitive data)
5. âœ… ğŸ§  LLM infrastructure (llama.cpp + open-webui with P2000 GPU)
6. âœ… nginx reverse proxy with Cloudflare tunnels
7. âœ… Cloudflare Access policies automated
8. âœ… 20+ Docker Compose services with systemd integration
9. âœ… Grafana + MySQL consolidated stack
10. âœ… ComfyUI with automated model management
11. âœ… n8n workflow automation with PostgreSQL
12. âœ… Media stack (Plex, Sonarr, Radarr, Prowlarr, etc.)
13. âœ… Prometheus monitoring
14. âœ… CMS platforms (PayloadCMS, Strapi, TinaCMS)

## Monitoring

1. ğŸ”„ ğŸ“Š DNS Prometheus exporter & dashboard (Exporter ready, needs testing + K8s dashboard)

# ğŸ“‹ Priority Todo List - Organized by Dependencies

## Phase 1: Foundation Infrastructure (No dependencies)

1. âŒ ğŸ”¢ Renumber IP network change subnet from /24 to /16
2. âŒ ğŸŒ DHCP Prometheus exporter & dashboard
3. âŒ ğŸ•³ï¸ Pi-hole .local domain passthrough or configure DNS properly
4. âŒ ğŸ“Š Complete DNS Prometheus exporter testing + add K8s dashboard
5. âŒ ğŸš¨ AlertManager and alerts for critical components (depends on Prometheus âœ…)

## Phase 2: Control Plane & Automation (Requires Phase 1)

1. âŒ ğŸ¦Š GitLab Ansible playbook on control-plane metal
2. âŒ ğŸ“¡ PXE TFTP setup for automated OS installs
3. âŒ ğŸ­ Ansible Semaphore or Rundeck deployment (requires GitLab)
4. âŒ ğŸ“– Runbook on control-plane metal deployed by GitLab
5. âŒ ğŸ’¡ List ideas for runbook tasks
6. âŒ ğŸ¤– Ansible automate VM creation

## Phase 3: Proxmox Migration (Requires Phase 2)

1. âŒ ğŸ’¾ Decide on Proxmox boot disk configuration
2. âŒ âš™ï¸ Proxmox automated installation w/ PXE, TFTP, DHCP
3. âŒ ğŸ“¦ Port ZFS pool to node006 Proxmox
4. âŒ ğŸ“¥ Proxmox import existing ZFS pool
5. âŒ ğŸ–¥ï¸ Create VM with ocean SSD passthrough
6. âŒ âš¡ Proxmox HA for both metals

## Phase 4: Kubernetes Cluster (Requires Phase 3)

1. âŒ â˜¸ï¸ Deploy base Kubernetes cluster
2. âŒ ğŸ Kubernetes Cilium networking
3. âŒ ğŸŒ iBGP internally with MetalLB
4. âŒ ğŸ“Š KubeDash admin interface
5. âŒ ğŸ“ Loki for log aggregation (all services, systems, K8s)
6. âŒ ğŸ” cert-manager for Let's Encrypt automation
7. âŒ ğŸ“Š etcd exporter + Grafana dashboards
8. âŒ ğŸ“ˆ Grafana dashboards for apiserver, HAProxy, VRRP, keepalived
9. âŒ ğŸ”„ Kubernetes ArgoCD private GitHub repo
10. âŒ ğŸ“ˆ Update all Helm charts with ArgoCD automation

## Phase 5: Advanced Kubernetes Features (Requires Phase 4)

1. âŒ ğŸ® Multi-instance GPU support in Kubernetes
2. âŒ ğŸ·ï¸ Taints for worker nodes with data01 and/or GPU
3. âŒ ğŸ¦™ Ollama Helm app install
4. âŒ ğŸ§  LLM on Kubernetes (migrate from Docker)
5. âŒ ğŸ“¦ Local container registry

## Phase 6: Service Discovery & Advanced Networking (Can parallelize with Phase 4-5)

1. âŒ ğŸ” Consul DNS for Docker container service discovery
2. âŒ ğŸ“ Registrator for Docker containers
3. âŒ ğŸŒ Nginx auto service discovery proxy backends

## Phase 7: Expansion Hardware (Can parallelize with Phase 4-6)

1. âŒ ğŸ¥§ Proxmox Raspberry Pi 5
2. âŒ â˜¸ï¸ Kubernetes VM worker on Pi-5
3. âŒ ğŸ·ï¸ Kubernetes ARM pod affinity

## Phase 8: DR & Resilience (Ongoing, starts after Phase 3)

1. âŒ ğŸš¨ DR plan for all services config and data
2. âŒ ğŸ› ï¸ Resiliency and Redundancy implementation
3. âŒ âš¡ HA for DNS, DHCP, LoadBalancer

# ğŸ¦Š GitLab Automation (Part of Phase 2)

1. âŒ ğŸ”„ GitLab pulls from github.com or is triggered via webhook
2. âŒ ğŸ  Homelab repo in GitLab triggers build steps on repo update
3. âŒ ğŸ­ Homelab repo uses Ansible Semaphore or Rundeck in a container
4. âŒ ğŸ”‘ The runner needs access to a private SSH key allowed on the internal hosts
5. âœ… â™»ï¸ The automation then applies all playbooks, so they all need to be idempotent