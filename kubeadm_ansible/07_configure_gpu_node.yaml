- name: Configure GPU nodes for workloads on Debian Bookworm
  hosts: k8s_worker
  become: yes
  tasks:
    - name: Check if GPU configuration is enabled
      debug:
        msg: "GPU configuration is enabled for this host."
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool

    - name: Install NVIDIA GPU driver
      apt:
        name: "{{ nvidia_driver_version }}"
        state: present
        update_cache: yes
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool
      vars:
        nvidia_driver_version: "nvidia-driver"

    - name: Install dependencies for NVIDIA Container Toolkit
      apt:
        name:
          - software-properties-common
          - apt-transport-https
          - ca-certificates
        state: present
        update_cache: yes
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool

    - name: Add NVIDIA Container Toolkit repository
      shell: |
        curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo tee /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
        distribution=$(. /etc/os-release; echo $ID$VERSION_ID)
        curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool

    - name: Install NVIDIA Container Toolkit for containerd
      apt:
        name: nvidia-container-toolkit
        state: present
        update_cache: yes
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool

    - name: Configure containerd to use NVIDIA runtime
      copy:
        dest: /etc/containerd/config.toml
        content: |
          version = 2

          [plugins."io.containerd.grpc.v1.cri".containerd]
            snapshotter = "overlayfs"
            default_runtime_name = "runc"
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
              [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.nvidia]
                runtime_type = "io.containerd.runtime.v1.linux"
                runtime_engine = ""
                runtime_root = ""
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool

    - name: Restart containerd service
      systemd:
        name: containerd
        state: restarted
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool

    - name: Deploy NVIDIA device plugin for Kubernetes
      kubernetes.core.k8s:
        state: present
        namespace: kube-system
        definition:
          apiVersion: apps/v1
          kind: DaemonSet
          metadata:
            name: nvidia-device-plugin-daemonset
            labels:
              name: nvidia-device-plugin
          spec:
            selector:
              matchLabels:
                name: nvidia-device-plugin
            template:
              metadata:
                labels:
                  name: nvidia-device-plugin
              spec:
                containers:
                - name: nvidia-device-plugin-ctr
                  image: "nvidia/k8s-device-plugin:1.0.0-beta"
                  env:
                  - name: "NVIDIA_VISIBLE_DEVICES"
                    value: "all"
                  - name: "NVIDIA_DRIVER_CAPABILITIES"
                    value: "compute,utility"
                  volumeMounts:
                  - name: device-plugin
                    mountPath: /var/lib/kubelet/device-plugins
                volumes:
                - name: device-plugin
                  hostPath:
                    path: /var/lib/kubelet/device-plugins
      when: hostvars[inventory_hostname].enable_gpu is defined and hostvars[inventory_hostname].enable_gpu | bool
